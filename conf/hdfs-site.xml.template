<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>
  <name>dfs.support.append</name>
  <value>true</value>
  <description>Allow append support since we have the HDFS-200 patch and
               need append/close support for HLog.java#splitLog</description>
</property>

<property>
  <name>dfs.blockreport.intervalMsec</name>
  <value>30000</value>
  <description>How long before each datanode reports about the blocks it has in ms</description>
</property>

<property>
  <name>dfs.replication</name>
  <value>2</value>
</property>

<property>
  <name>raid.config.file</name>
  <value>/app/hadoop/conf/raid.xml</value>
  <description>This is needed by the RaidNode </description>
</property>

<property>
  <name>fs.hdfs.impl</name>
  <value>org.apache.hadoop.hdfs.DistributedFileSystem</value>
  <description>The FileSystem for hdfs: uris.</description>
</property>

<property>
  <name>raid.classname</name>
  <value>org.apache.hadoop.raid.DistRaidNode</value>
  <description>Specify which implementation of RaidNode to use (class name).</description>
</property>
  
<property>
  <name>raid.policy.rescan.interval</name>
  <value>30000</value>
  <description>Specify the periodicity in milliseconds after which
  all source paths are rescanned and parity blocks recomputed if
  necessary. By default, this value is 1 hour.
  </description>
</property>

<property>
  <name>dfs.permissions</name>
  <value>false</value>
  <description>Check for superuser privileges?</description>
</property>

<property>
  <name>dfs.block.replicator.classname</name>
  <value>org.apache.hadoop.hdfs.server.namenode.BlockPlacementPolicyRaid</value>
  <description>Placement policy</description>
</property>

<property>
  <name>hdfs.raid.stripeLength</name>
  <value>10</value>
  <description>The stripe length for the code. stripeLength number of blocks are used for coding for RS coding</description>
</property>

<property>
  <name>hdfs.raidrs.paritylength</name>
  <value>4</value>
  <description>The number of parity blocks generated from stripeLength number of blocks if pure RS coding is used (FB's version). 
  This should not be accessed, but is in place for safety, just so if master branch is used along with this hdfs-site file</description>
</property>

<property>
  <name>hdfs.raidrs.rsparitylength</name>
  <value>4</value>
  <description>The number of RS parity blocks generated from stripeLength number of blocks</description>
</property>

<property>
  <name>hdfs.raidrs.srcparitylength</name>
  <value>2</value>
  <description>The number of SRC blocks. If its zero we will use pure RS</description>
</property>

<property>
  <name>raid.blockfix.classname</name>
  <value>org.apache.hadoop.raid.DistBlockIntegrityMonitor</value>
  <description>Specify the BlockFixer implementation to use.
    The default is org.apache.hadoop.raid.DistBlockFixer.
  </description>
</property>
  
<property>
  <name>raid.blockfix.interval</name>
  <value>30000</value>
  <description>interval in milliseconds between checks for lost files. Default is 1 minute</description>
</property>

<property>
  <name>dfs.heartbeat.interval</name>
  <value>3</value>
  <description>Determines datanode heartbeat interval in
seconds.</description>
</property>

<property>
  <name>heartbeat.recheck.interval</name>
  <value>15000</value>
  <description>Heartbeat recheck interval in ms. The data node expire interval is 
10*dfs.heartbeat.interval + 2*heartbeat.recheck.interval</description>
</property>

<property>
  <name>dfs.block.size</name>
  <value>67108864</value>
  <description>The default block size for new files.</description>
</property>

</configuration>
